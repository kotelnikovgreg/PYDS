{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c567f4a",
   "metadata": {},
   "source": [
    "### Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99611a59",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182c466",
   "metadata": {},
   "source": [
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994985e5",
   "metadata": {},
   "source": [
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random state должен быть равен 42.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbdcca",
   "metadata": {},
   "source": [
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26012f",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычисли"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61ea2d",
   "metadata": {},
   "source": [
    "Вычислите R2 полученных предсказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47242e4d",
   "metadata": {},
   "source": [
    "#### Задание 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec857e23",
   "metadata": {},
   "source": [
    "Создайте модель под названием model с помощью класса RandomForestRegressor из модуля sklearn.ensemble.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462978b1",
   "metadata": {},
   "source": [
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e2700",
   "metadata": {},
   "source": [
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ce528",
   "metadata": {},
   "source": [
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd05a4",
   "metadata": {},
   "source": [
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18289bfa",
   "metadata": {},
   "source": [
    "#### Задание 3 \n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d5548",
   "metadata": {},
   "source": [
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03872d7c",
   "metadata": {},
   "source": [
    "#### Задание 4\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97c8c1",
   "metadata": {},
   "source": [
    "### **Задание на повторение материала"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487676a",
   "metadata": {},
   "source": [
    "1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.\n",
    "2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "3). Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.\n",
    "4). Сколько классов содержит целевая переменная датасета? Выведите названия классов.\n",
    "5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X.\n",
    "6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.\n",
    "8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список).\n",
    "10). Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24028cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
